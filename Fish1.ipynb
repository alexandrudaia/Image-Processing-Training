{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import  keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 photos of ALB\n",
      "200 photos of BET\n",
      "117 photos of DOL\n",
      "67 photos of LAG\n",
      "465 photos of NoF\n",
      "299 photos of OTHER\n",
      "176 photos of SHARK\n",
      "734 photos of YFT\n",
      "3777\n",
      "3777\n",
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777\n",
      "(3777, 120, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR='/media/machine_learning/A80C461E0C45E7C01/leiden/train/train/'\n",
    "\n",
    "TEST_DIR='C:/Users/alexandru.daia/Documents/Downloads/test_stg1/'\n",
    "\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "\n",
    "\n",
    " \n",
    "COLS = 160 #1280\n",
    "\n",
    "COLS = 160 #1280\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "ROWS = 120  #720\n",
    "COLS = 180 #1280\n",
    "CHANNELS = 3\n",
    "TRAIN_DIR='C:/Users/alexandru.daia/Documents/Downloads/train/train/'\n",
    "\n",
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "#def read_image(src):\n",
    "#    \"\"\"Read and resize individual images\"\"\"\n",
    "#    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "#    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "#    return im\n",
    "def read_image(src):\n",
    "    import os\n",
    "    from scipy import misc\n",
    "    filepath=src\n",
    "    im=misc.imread(filepath)\n",
    "    import scipy.misc  as mc\n",
    "     \n",
    "    return mc.imresize(im,(ROWS,COLS))\n",
    "#grandPadre=read_gray_scale()\n",
    "\n",
    "\n",
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)\n",
    "print(len(files))\n",
    "print(len(y_all))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)\n",
    "# One Hot Encoding Labels\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = np_utils.to_categorical(y_all)\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3777, 120, 180, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2416 samples, validate on 605 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "def center_normalize(x):\n",
    "    return (x - K.mean(x)) / K.std(x)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(FISH_CLASSES)))\n",
    "model.add(Activation('sigmoid'))\n",
    "sgd = SGD(lr=1e-2, decay=1e-4, momentum=0.88, nesterov=False)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "        \n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=30,\n",
    "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])\n",
    "preds = model.predict(X_valid, verbose=1)\n",
    "print(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(TEST_DIR+im)\n",
    "    \n",
    "test_preds = model.predict(test, verbose=1)\n",
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()\n",
    "\n",
    "submission.to_csv('C:/Users/alexandru.daia/Documents/Downloads/sub1Fish.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00005.jpg</td>\n",
       "      <td>0.937935</td>\n",
       "      <td>0.274359</td>\n",
       "      <td>0.146646</td>\n",
       "      <td>0.085808</td>\n",
       "      <td>0.452689</td>\n",
       "      <td>0.270545</td>\n",
       "      <td>0.180672</td>\n",
       "      <td>0.748145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.933769</td>\n",
       "      <td>0.281047</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>0.093755</td>\n",
       "      <td>0.455361</td>\n",
       "      <td>0.277481</td>\n",
       "      <td>0.188669</td>\n",
       "      <td>0.734519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009.jpg</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>0.294056</td>\n",
       "      <td>0.172802</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.456513</td>\n",
       "      <td>0.298595</td>\n",
       "      <td>0.207577</td>\n",
       "      <td>0.720324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00018.jpg</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>0.267197</td>\n",
       "      <td>0.132652</td>\n",
       "      <td>0.078323</td>\n",
       "      <td>0.451446</td>\n",
       "      <td>0.262309</td>\n",
       "      <td>0.169907</td>\n",
       "      <td>0.750009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00027.jpg</td>\n",
       "      <td>0.936968</td>\n",
       "      <td>0.275603</td>\n",
       "      <td>0.149411</td>\n",
       "      <td>0.088170</td>\n",
       "      <td>0.449033</td>\n",
       "      <td>0.276973</td>\n",
       "      <td>0.183767</td>\n",
       "      <td>0.745346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_00005.jpg  0.937935  0.274359  0.146646  0.085808  0.452689  0.270545   \n",
       "1  img_00007.jpg  0.933769  0.281047  0.151735  0.093755  0.455361  0.277481   \n",
       "2  img_00009.jpg  0.919614  0.294056  0.172802  0.109556  0.456513  0.298595   \n",
       "3  img_00018.jpg  0.945400  0.267197  0.132652  0.078323  0.451446  0.262309   \n",
       "4  img_00027.jpg  0.936968  0.275603  0.149411  0.088170  0.449033  0.276973   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.180672  0.748145  \n",
       "1  0.188669  0.734519  \n",
       "2  0.207577  0.720324  \n",
       "3  0.169907  0.750009  \n",
       "4  0.183767  0.745346  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
